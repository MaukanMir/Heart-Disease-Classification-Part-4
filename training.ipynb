{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import Counter\n",
    "\n",
    "\n",
    "# Models \n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.gaussian_process import GaussianProcessClassifier\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "# Data Processing\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "from scipy.stats import entropy\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# MLP\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "\n",
    "# Model Processing\n",
    "from sklearn.dummy import DummyClassifier\n",
    "from sklearn.metrics import fbeta_score, make_scorer\n",
    "from sklearn.model_selection import RepeatedStratifiedKFold, cross_val_score\n",
    "from sklearn.pipeline import Pipeline\n",
    "from imblearn.pipeline import Pipeline as imblearnPipeline\n",
    "from sklearn.preprocessing import PowerTransformer\n",
    "\n",
    "from imblearn.under_sampling import TomekLinks\n",
    "from imblearn.over_sampling import BorderlineSMOTE\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from imblearn.over_sampling import ADASYN\n",
    "from imblearn.combine import SMOTETomek\n",
    "from imblearn.combine import SMOTEENN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def spot_check_models(X_train_scaled, X_test_scaled, y_train_encoded, y_test_encoded):\n",
    "    \"\"\"\n",
    "    This a quick way to spot check relevant algorithms to gain an understanding of \n",
    "    the dataset and which models handle the distribution well.\n",
    "\n",
    "    Args:\n",
    "        X_train_scaled (_type_): _description_\n",
    "        X_test_scaled (_type_): _description_\n",
    "        y_train_encoded (_type_): _description_\n",
    "        y_test_encoded (_type_): _description_\n",
    "\n",
    "    Returns:\n",
    "        _type_: Sorted dataframe on accuracy scores.\n",
    "    \"\"\"\n",
    "    models = {\n",
    "        \n",
    "        \"GaussianNB\": GaussianNB(),\n",
    "        \"LDA\":LinearDiscriminantAnalysis(),\n",
    "        \"GPC\":GaussianProcessClassifier(),\n",
    "        \n",
    "        \"LogisticRegression\": LogisticRegression(),\n",
    "        \"SVC\": SVC(),\n",
    "        \"KNeighborsClassifier\": KNeighborsClassifier(),\n",
    "        \n",
    "        \"DecisionTreeClassifier\": DecisionTreeClassifier(random_state=42),\n",
    "        \"RandomForestClassifier\": RandomForestClassifier(random_state=42),\n",
    "        \"GradientBoostingClassifier\": GradientBoostingClassifier(random_state=42),\n",
    "        \"XGB\":XGBClassifier()\n",
    "    }\n",
    "\n",
    "    # Create an empty DataFrame to store model performance\n",
    "    model_performance = []\n",
    "\n",
    "    for name, model in models.items():\n",
    "        model.fit(X_train_scaled, y_train_encoded)\n",
    "        predictions = model.predict(X_test_scaled)\n",
    "        accuracy = accuracy_score(y_test_encoded, predictions)\n",
    "        model_performance.append({\n",
    "            \"Model\": name,\n",
    "            \"Accuracy\": accuracy\n",
    "        })\n",
    "\n",
    "    # For the Sequential model\n",
    "    sequential_model = Sequential()\n",
    "    sequential_model.add(Dense(64, input_dim=X_train_scaled.shape[1], activation='relu'))\n",
    "    sequential_model.add(Dense(32, activation='relu'))\n",
    "    sequential_model.add(Dense(1, activation='sigmoid'))\n",
    "    sequential_model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "    sequential_model.fit(X_train_scaled, y_train_encoded, epochs=50, batch_size=10, verbose=0)\n",
    "    loss, accuracy = sequential_model.evaluate(X_test_scaled, y_test_encoded)\n",
    "    model_performance.append({\n",
    "        \"Model\": \"Sequential\",\n",
    "        \"Accuracy\": accuracy\n",
    "    })\n",
    "\n",
    "    # Convert the model_performance to a DataFrame\n",
    "    performance_df = pd.DataFrame(model_performance)\n",
    "    return performance_df.sort_values(by=\"Accuracy\", ascending=False)\n",
    "\n",
    "\n",
    "def get_selected_models(names):\n",
    "  \"\"\"\n",
    "  Returns selected models for ML processing\n",
    "\n",
    "  Args:\n",
    "      names (_type_):List\n",
    "\n",
    "  Returns:\n",
    "      List of models\n",
    "  \"\"\"\n",
    "  models = {\n",
    "    \"LDA\": LinearDiscriminantAnalysis(),\n",
    "    \"GPC\": GaussianProcessClassifier(),\n",
    "    \"GNB\": GaussianNB(),\n",
    "    \"SVC\": SVC(),\n",
    "    \"LR\":LogisticRegression(max_iter=1000),\n",
    "    \"KNN\": KNeighborsClassifier(),\n",
    "    \"DTC\": DecisionTreeClassifier(),\n",
    "    \"GBC\":GradientBoostingClassifier(),\n",
    "    \"RFC\":RandomForestClassifier(),\n",
    "    \"XGB\": XGBClassifier()\n",
    "  }\n",
    "  \n",
    "  return [models[model] for model in names]\n",
    "\n",
    "def f2_measure(y_true, y_pred):\n",
    "  return fbeta_score(y_true, y_pred, beta=2)\n",
    "\n",
    "def evaluate_model(X, y, model):\n",
    "  # define evaluation procedure\n",
    "  cv = RepeatedStratifiedKFold(n_splits=10, n_repeats=3, random_state=1)\n",
    "  \n",
    "  metric = make_scorer(f2_measure)\n",
    "  # evaluate model\n",
    "  scores = cross_val_score(model, X, y, scoring=metric, cv=cv, n_jobs=-1)\n",
    "  return scores\n",
    "\n",
    "def labels_to_probabilities(y):\n",
    "    values, counts = np.unique(y, return_counts=True)\n",
    "    probabilities = counts / counts.sum()\n",
    "    return probabilities\n",
    "\n",
    "def calculate_entropy(df:pd.DataFrame)-> pd.DataFrame:\n",
    "  \"\"\"_summary_\n",
    "\n",
    "  Args:\n",
    "      df (pd.DataFrame): Pandas DataFrame\n",
    "\n",
    "  Returns:\n",
    "      pd.DataFrame: THe Entropy level of all models\n",
    "  \"\"\"\n",
    "\n",
    "  column_entropy_info = {}\n",
    "  for col in df.columns:\n",
    "    probabilities = labels_to_probabilities(df[col])\n",
    "    entropy_value = entropy(probabilities, base=2)\n",
    "    column_entropy_info[col] = {\n",
    "          'entropy': entropy_value\n",
    "      }\n",
    "\n",
    "  return pd.DataFrame(column_entropy_info)\n",
    "\n",
    "def testing_selected_models(names:list, models:list, X:pd.DataFrame, y:pd.Series):\n",
    "    \"\"\"\n",
    "    Runs multiple subsets on folds of data\n",
    "\n",
    "    Args:\n",
    "        names (list): _description_\n",
    "        models (list): _description_\n",
    "    \"\"\"\n",
    "    \n",
    "    for i in range(len(models)):\n",
    "        pipeline = Pipeline(steps=[('scaler', StandardScaler()), (\"power_tranformer\",PowerTransformer()), ('model', models[i])])\n",
    "        # Evaluate the model\n",
    "        scores = evaluate_model(X, y, pipeline)\n",
    "        # summarize and store\n",
    "        print('>%s %.3f (%.3f)' % (names[i], np.mean(scores), np.std(scores)))\n",
    "\n",
    "def grid_search_selected_models(param_grid:dict,names:list, models:list, X:pd.DataFrame, y:pd.Series, metric):\n",
    "    \"\"\"\n",
    "    Runs multiple subsets on folds of data\n",
    "\n",
    "    Args:\n",
    "        names (list): _description_\n",
    "        models (list): _description_\n",
    "    \"\"\"\n",
    "    \n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.20, random_state=42)\n",
    "\n",
    "    model_performance = []\n",
    "\n",
    "    for i in range(len(models)):\n",
    "        model, name = models[i], names[i]\n",
    "        pipeline = Pipeline([\n",
    "                ('scaler', StandardScaler()),\n",
    "                ('power_transformer', PowerTransformer()),\n",
    "                ('model', model)\n",
    "        ])\n",
    "            \n",
    "        grid_search = GridSearchCV(pipeline, param_grid[name], cv=5, scoring=metric, n_jobs=-1)\n",
    "        grid_search.fit(X_train, y_train)\n",
    "        best_model = grid_search.best_estimator_\n",
    "            \n",
    "        # Predict on the test set\n",
    "        y_pred = best_model.predict(X_test)\n",
    "        accuracy = accuracy_score(y_test, y_pred)\n",
    "        \n",
    "        f2 = f2_measure(y_test, y_pred)\n",
    "            \n",
    "        print(f'Best score for {name}: {grid_search.best_score_:.3f}')\n",
    "        print(\"Best parameters:\", grid_search.best_params_)\n",
    "        \n",
    "        print(f'Test accuracy for {name}: {accuracy:.3f}')\n",
    "        print(f\"F2 Score: {f2:.3f}\")\n",
    "        print(\"---------------------------------------------------------------\")\n",
    "        \n",
    "        conf_mat = confusion_matrix(y_test, y_pred)\n",
    "        # Plot the confusion matrix\n",
    "        plt.figure(figsize=(8,6))\n",
    "        sns.heatmap(conf_mat, annot=True, fmt='d', cmap='Blues')\n",
    "        plt.xlabel('Predicted Labels')\n",
    "        plt.ylabel('True Labels')\n",
    "        plt.title(f'Confusion Matrix for {names[i]}')\n",
    "        plt.show()\n",
    "            \n",
    "        model_performance.append({\n",
    "                \"Model\": name,\n",
    "                \"Best CV Score\": grid_search.best_score_,\n",
    "                \"Test Accuracy\": accuracy,\n",
    "                'F2 Score':f2,\n",
    "                \"Best Parameters\": grid_search.best_params_\n",
    "        })\n",
    "\n",
    "\n",
    "    model_performance_df = pd.DataFrame(model_performance)\n",
    "    print(model_performance_df)\n",
    "    \n",
    "def get_under_over_sampling_models(names:list):\n",
    "    \"\"\"\n",
    "        Returns list of under sampling models\n",
    "\n",
    "        Args:\n",
    "            names (list): _description_\n",
    "    \"\"\"\n",
    "        \n",
    "    models = {\n",
    "        \"SMOTE\": SMOTE(),\n",
    "        \"BLS\": BorderlineSMOTE(),\n",
    "        \"ADA\": ADASYN(),\n",
    "        \"TL\":TomekLinks(),\n",
    "        \"SMOTE-TOMEK\": SMOTETomek(tomek=TomekLinks(sampling_strategy='majority')),\n",
    "        \"SMOTE + KKN\":SMOTEENN()\n",
    "    }  \n",
    "    return [models[model] for model in names]\n",
    "\n",
    "def test_selected_sampling_models(names:list, models:list, X:pd.DataFrame, y:pd.Series, model):\n",
    "    \"\"\"\n",
    "    Test best model on multiple sampling subsets\n",
    "\n",
    "    Args:\n",
    "        names (list): _description_\n",
    "        models (list): _description_\n",
    "        X (pd.DataFrame): _description_\n",
    "        y (pd.Series): _description_\n",
    "        metric (_type_): _description_\n",
    "        model (_type_): _description_\n",
    "    \"\"\"\n",
    "\n",
    "    for i in range(len(models)):\n",
    "        pipeline = imblearnPipeline(steps=[\n",
    "            ('scaler', StandardScaler()), \n",
    "            (\"power_tranformer\",PowerTransformer()), \n",
    "            ('sampling', models[i]),\n",
    "            (\"model\", model)\n",
    "            ])\n",
    "        # Evaluate the model\n",
    "        scores = evaluate_model(X, y, pipeline)\n",
    "        # summarize and store\n",
    "        print('>%s %.3f (%.3f)' % (names[i], np.mean(scores), np.std(scores)))\n",
    "\n",
    "def test_final_model(X,y, names, models, final_model):\n",
    "    \"\"\"_summary_\n",
    "\n",
    "    Args:\n",
    "        X (_type_): _description_\n",
    "        y (_type_): _description_\n",
    "        names (_type_): _description_\n",
    "        model (_type_): _description_\n",
    "    \"\"\"\n",
    "    \n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.20, random_state=42)\n",
    "\n",
    "    model_performance = []\n",
    "\n",
    "    for i in range(len(models)):\n",
    "        model, name = models[i], names[i]\n",
    "        pipeline = imblearnPipeline(steps=[\n",
    "            ('scaler', StandardScaler()), \n",
    "            (\"power_tranformer\",PowerTransformer()), \n",
    "            ('sampling', models[i]),\n",
    "            (\"model\", final_model)\n",
    "            ])\n",
    "        \n",
    "        pipeline.fit(X_train, y_train)\n",
    "        # Predict on the test set\n",
    "        y_pred = pipeline.predict(X_test)\n",
    "        accuracy = accuracy_score(y_test, y_pred)\n",
    "        \n",
    "        f2 = f2_measure(y_test, y_pred)\n",
    "        \n",
    "        print(f'Test accuracy for {name}: {accuracy:.3f}')\n",
    "        print(f\"F2 Score: {f2:.3f}\")\n",
    "        print(\"---------------------------------------------------------------\")\n",
    "        \n",
    "        conf_mat = confusion_matrix(y_test, y_pred)\n",
    "        # Plot the confusion matrix\n",
    "        plt.figure(figsize=(8,6))\n",
    "        sns.heatmap(conf_mat, annot=True, fmt='d', cmap='Blues')\n",
    "        plt.xlabel('Predicted Labels')\n",
    "        plt.ylabel('True Labels')\n",
    "        plt.title(f'Confusion Matrix for {names[i]}')\n",
    "        plt.show()\n",
    "            \n",
    "        model_performance.append({\n",
    "                \"Model\": name,\n",
    "                \"Test Accuracy\": accuracy,\n",
    "                'F2 Score':f2,\n",
    "        })\n",
    "\n",
    "\n",
    "    model_performance_df = pd.DataFrame(model_performance)\n",
    "    print(model_performance_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# EDA Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>sex</th>\n",
       "      <th>chest pain type</th>\n",
       "      <th>resting bp s</th>\n",
       "      <th>cholesterol</th>\n",
       "      <th>fasting blood sugar</th>\n",
       "      <th>resting ecg</th>\n",
       "      <th>max heart rate</th>\n",
       "      <th>exercise angina</th>\n",
       "      <th>oldpeak</th>\n",
       "      <th>ST slope</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>40</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>140</td>\n",
       "      <td>289</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>172</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>49</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>160</td>\n",
       "      <td>180</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>156</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>37</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>130</td>\n",
       "      <td>283</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>98</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>48</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>138</td>\n",
       "      <td>214</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>108</td>\n",
       "      <td>1</td>\n",
       "      <td>1.5</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>54</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>150</td>\n",
       "      <td>195</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>122</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1185</th>\n",
       "      <td>45</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>110</td>\n",
       "      <td>264</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>132</td>\n",
       "      <td>0</td>\n",
       "      <td>1.2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1186</th>\n",
       "      <td>68</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>144</td>\n",
       "      <td>193</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>141</td>\n",
       "      <td>0</td>\n",
       "      <td>3.4</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1187</th>\n",
       "      <td>57</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>130</td>\n",
       "      <td>131</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>115</td>\n",
       "      <td>1</td>\n",
       "      <td>1.2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1188</th>\n",
       "      <td>57</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>130</td>\n",
       "      <td>236</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>174</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1189</th>\n",
       "      <td>38</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>138</td>\n",
       "      <td>175</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>173</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1190 rows Ã— 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      age  sex  chest pain type  resting bp s  cholesterol  \\\n",
       "0      40    1                2           140          289   \n",
       "1      49    0                3           160          180   \n",
       "2      37    1                2           130          283   \n",
       "3      48    0                4           138          214   \n",
       "4      54    1                3           150          195   \n",
       "...   ...  ...              ...           ...          ...   \n",
       "1185   45    1                1           110          264   \n",
       "1186   68    1                4           144          193   \n",
       "1187   57    1                4           130          131   \n",
       "1188   57    0                2           130          236   \n",
       "1189   38    1                3           138          175   \n",
       "\n",
       "      fasting blood sugar  resting ecg  max heart rate  exercise angina  \\\n",
       "0                       0            0             172                0   \n",
       "1                       0            0             156                0   \n",
       "2                       0            1              98                0   \n",
       "3                       0            0             108                1   \n",
       "4                       0            0             122                0   \n",
       "...                   ...          ...             ...              ...   \n",
       "1185                    0            0             132                0   \n",
       "1186                    1            0             141                0   \n",
       "1187                    0            0             115                1   \n",
       "1188                    0            2             174                0   \n",
       "1189                    0            0             173                0   \n",
       "\n",
       "      oldpeak  ST slope  target  \n",
       "0         0.0         1       0  \n",
       "1         1.0         2       1  \n",
       "2         0.0         1       0  \n",
       "3         1.5         2       1  \n",
       "4         0.0         1       0  \n",
       "...       ...       ...     ...  \n",
       "1185      1.2         2       1  \n",
       "1186      3.4         2       1  \n",
       "1187      1.2         2       1  \n",
       "1188      0.0         2       1  \n",
       "1189      0.0         1       0  \n",
       "\n",
       "[1190 rows x 12 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"heart_statlog_cleveland_hungary_final.csv\")\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Check for Dupe values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Null values: age                    0\n",
      "sex                    0\n",
      "chest pain type        0\n",
      "resting bp s           0\n",
      "cholesterol            0\n",
      "fasting blood sugar    0\n",
      "resting ecg            0\n",
      "max heart rate         0\n",
      "exercise angina        0\n",
      "oldpeak                0\n",
      "ST slope               0\n",
      "target                 0\n",
      "dtype: int64\n",
      "Total number of duplicate values: 272\n"
     ]
    }
   ],
   "source": [
    "print(f\"Total Null values: {df.isna().sum()}\")\n",
    "print(f\"Total number of duplicate values: {df.duplicated().sum()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop_duplicates(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "machine-learning-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
